{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Notebook 6: A Linear Algebra Refresher\n",
    "---\n",
    "**Agenda**\n",
    "1. Revise Eigenvalues and Eigenvectors\n",
    "1. Norms of Vectors and Matrices\n",
    "1. Special Matrices \n",
    "1. Finite Precision Mathematics on a Computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "#IMPORT\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "#from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "#import ipywidgets as widgets\n",
    "\n",
    "## Set a seed for the random number generator\n",
    "np.random.seed(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Eigenvalues and eigenvectors\n",
    "<hr>\n",
    "\n",
    "An eigenvector of a square matrix $A$ is a special non-zero vector such that\n",
    "$$ A v  = \\lambda v$$\n",
    "where $\\lambda$ is called the associated eigenvalue.\n",
    "\n",
    "**Example**: Find the eigenvalues and eigenvectors of \n",
    "$\n",
    "A = \\left( \\begin{array}{cc} 2 & 4  \\\\\n",
    "1 & -1 \n",
    "\\end{array}\n",
    "\\right) \n",
    "$\n",
    "##### Discussion about solving characteristic polynomials.\n",
    "**Example** Find the eigenvalues of the matrix $B = f(A)$ where $f(x) = x^2-3x +5$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cayley-Hamilton Theorem\n",
    "\n",
    "Every square matrix satisfies its characteristic polynomial. Let $A \\in \\mathbb{R}^{n \\times n}$\n",
    "$$\n",
    "p(\\lambda) = det (A - \\lambda I) = 0 \\Rightarrow p(A) = 0 \\in \\mathbb{R}^{n \\times n}\n",
    "$$\n",
    "\n",
    "---\n",
    "**Questions** How can Cayley-Hamlton Theorem be used for the following?\n",
    "1. Inverse of a matrix.\n",
    "1. Powers of a matrix.\n",
    "1. Evaluating other polynomials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]]\n",
      "[[0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "I = np.eye(4)\n",
    "print(I)\n",
    "p = np.array([2,0,3,1])\n",
    "\n",
    "P = I[p,:]\n",
    "print(P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "---\n",
    "### Eigen-decomposition\n",
    "\n",
    "If the square matrix $A\\in \\mathbb{C}^{n\\times n}$ has $n$ linearly independent eigenvectors  then $A$ can be given in the following factorized form as\n",
    "$$\n",
    "A = Q \\Lambda Q^{-1},\n",
    "$$\n",
    "where $\\Lambda = $ diag$(\\lambda_1, \\cdots, \\lambda_n)$ and columns of matrix $Q$ are made of the eigenvector $q_i$ of $A$ $(i=1,\\cdots,n)$, arranged in the same order as the eigenvalues in $\\Lambda$.\n",
    ">- When $A$ is a real and symmetric matrix: $A = Q \\Lambda Q^T$, where $Q$ is orthogonal $(Q^TQ = I = QQ^T)$ and $\\Lambda$ is made of real diagonal entries.\n",
    ">- If a function $f(x)$ has power series expansion in $x$, then $f(A) = Q f(\\Lambda) Q^{-1}$ where \n",
    "$$f(\\Lambda) = \\text{diag} (f(\\lambda_1), f(\\lambda_2), \\cdots).$$\n",
    "\n",
    "#### Discussion on Spectral Decomposition and Projection\n",
    "When $A$ is a real and symmetric matrix: \n",
    "$$A = Q \\Lambda Q^T = \\sum_{k=1}^n \\lambda_k Q_{:k} Q_{:k}^T$$\n",
    "where $P_k  = Q_{:k} Q_{:k}^T$ is a rank-one projection matrix that orthogonally  projects any vector $v \\in \\mathbb{R}^n$ to the $k$-th eigenspace of $A$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Invertibility: A discussion\n",
    "---\n",
    "Please go to POLL EVERYWHERE for a quiz to visit the properties of inverses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Matrix A:\n",
      " [[2 3 2 5]\n",
      " [8 1 0 7]\n",
      " [6 2 0 8]\n",
      " [2 5 1 8]] \n",
      "\n",
      " Inverse if A:\n",
      " [[  -0.10714    0.60714   -0.67857    0.21429]\n",
      " [  -0.39286    0.89286   -1.32143    0.78571]\n",
      " [   0.75000   -0.25000    0.25000   -0.50000]\n",
      " [   0.17857   -0.67857    0.96429   -0.35714]]\n",
      "Verify inverse:\n",
      " [[   1.00000   -0.00000    0.00000    0.00000]\n",
      " [   0.00000    1.00000    0.00000   -0.00000]\n",
      " [   0.00000    0.00000    1.00000    0.00000]\n",
      " [   0.00000   -0.00000    0.00000    1.00000]]\n"
     ]
    }
   ],
   "source": [
    "## This setting restricts the dispaly of decimals to simpler forms\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:10.5f}\".format(x)})\n",
    "\n",
    "## Generate matrix of randoem integers for experiment\n",
    "A = np.random.randint(0,9, size=(4,4))\n",
    "\n",
    "##Finding inverse of a square matrix.\n",
    "invA = np.linalg.inv(A) \n",
    "\n",
    "print(\" Matrix A:\\n\",A,\"\\n\\n Inverse if A:\\n\", invA)\n",
    "\n",
    "print (\"Verify inverse:\\n\",np.dot(A,invA))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Vector and Matrix Norms\n",
    "---\n",
    "Continued on the whiteboard and worksheet.\n",
    "\n",
    "#### Manhattan distance (Taxi-cab distnace)\n",
    "<div style=\"width:500px\">\n",
    "<img src=\"./images/Manhattan_distance.png\" width=50%/>\n",
    "</div>\n",
    "\n",
    "[Image Source](https://en.wikipedia.org/wiki/Taxicab_geometry#/media/File:Manhattan_distance.svg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "In general, a norm is any function that assigns a real number to any vector, $\\|\\cdot\\|: V \\to \\mathbb{R}$, and that satisfies the following properties\n",
    "  \n",
    ">1. Nonnegativity: $\\|\\bf{v}\\| \\geq 0$.\n",
    ">1. Definiteness:  $\\|\\bf{v}\\| = 0 \\Leftrightarrow \\bf{v}=0$.\n",
    ">1. Homegeneity: For any real number $\\alpha$,  $\\|\\alpha \\bf{v}\\| = |\\alpha| \\|\\bf{v}\\|$.\n",
    ">1. Triangle law: $\\|\\bf{u} + \\bf{v}\\| \\leq \\|\\bf{u}\\| + \\|\\bf{v}\\|$.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From norms to a notion of distance (metric), $d:V \\times V \\to \\mathbb{R}$\n",
    "A metric on a set V satisfies the follwing for all $u,v,w \\in V$\n",
    "- $d(u,v)=0 \\Leftrightarrow u=v$ (identity)\n",
    "- $d(u,v)=d(v,u) $ (symmetry)\n",
    "- $d(u,v) \\le d(u,w)+d(w,v) $ (triangle law)\n",
    "\n",
    "Verify that $d(u,v) \\ge 0$.\n",
    "\n",
    ">- In the case of a normed vector space we can define a metric as $d(u,\\,v)=\\|v-u\\|$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "  EXAMPLES: Some norms on the space of $n$-dimensional vectors.\n",
    "  \n",
    ">- $l_1$ norm\n",
    "$$\n",
    "\\|x\\|_1 = \\sum\\limits_{i=1}^n \\ |x_i| = |x_1|+|x_2|+\\cdots+|x_n|\n",
    "$$\n",
    "\n",
    ">- $l_2$ norm\n",
    "$$\n",
    "\\|x\\|_2 = \\sqrt{ \\sum\\limits_{i=1}^n \\ x_i^2} = \\left(x_1^2+x_2^2+\\cdots+x_n^2\\right)^{1/2}\n",
    "$$\n",
    "\n",
    ">- $l_{p}$ norm\n",
    "$$\n",
    "\\|x \\|_p = \\left( \\sum\\limits_{i=1}^n \\ |x_i|^p \\right)^{1/p}= \n",
    "\\sqrt[p]{\\left(|x_1|^p+|x_2|^p+\\cdots+|x_n|^p \\right)}\n",
    "$$\n",
    ">- $l_{\\infty}$ norm\n",
    "$$ \\|x\\|_{\\infty} = \\max_{i=1,\\cdots,n} |x_i|$$\n",
    "\n",
    "**Example** Determine if the expression  defines a norm on $\\mathbb{R}^n$: \n",
    "$$\n",
    "f({\\bf x}) = \\sum\\limits_{i=1}^n |x_i|^3.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unit circles in $\\mathbb{R}^2$:  $\\|x\\|_1 \\leq 1$ and $\\|x\\|_2 \\leq 1$\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/f/f8/L1_and_L2_balls.svg\" width=\"80%\" />\n",
    "\n",
    "[Image Source: WikiMedia](https://upload.wikimedia.org/wikipedia/commons/f/f8/L1_and_L2_balls.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Matrix norms \n",
    "Matrix norms could be defined as an extension of vector norms by considering matrices as $mn$-dimensional vectors.\n",
    "#### Frobenius Norms\n",
    "$$\n",
    "\\|A\\|_F = \\left( \\sum\\limits_{i=1}^m \\sum\\limits_{j=1}^n a_{i,j}^2 \\right)^{1/2}.\n",
    "$$\n",
    "\n",
    "**Example**: Verify that $\\|A\\|_F = \\sqrt{\\operatorname{tr}(A^T A) }$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Matrix Norm Induced by a Vector Norm\n",
    "$$\n",
    "\\| A\\| = \\textrm{sup} \\left\\{   \\|Au\\|: u \\in \\mathbb{R}^n, \\|u\\| = 1 \\right\\}\n",
    "$$\n",
    "\n",
    " An important consequence is that the subordinate norm also satisfies\n",
    " \n",
    ">-\n",
    "$$\n",
    "\\|A x\\| \\leq \\|A\\| \\|x\\|\n",
    "$$\n",
    ">- Submultiplicative norm property\n",
    "$$\n",
    "\\|A B\\| \\leq \\|A\\| \\|B\\|\n",
    "$$\n",
    ">-\n",
    "$$\n",
    "\\|I\\| = 1\n",
    "$$\n",
    "\n",
    "EXAMPLES: Some induced matrix norms\n",
    "\n",
    ">- The subordinate matrix norm induced by  $\\|\\cdot\\|_{\\infty}$, called max-abs-row-sum norm, is given by\n",
    "$$\n",
    "\\|A\\|_{\\infty} = \\textrm{max}_{1 \\leq i \\leq n} \\sum\\limits_{j=1}^{n} |a_{ij}|\n",
    "$$\n",
    "\n",
    ">- The subordinate matrix norm induced by  $\\|\\cdot\\|_{1}$, called max-abs-column-sum norm, is given by\n",
    "$$\n",
    "\\|A\\|_{1} = \\textrm{max}_{1 \\leq j \\leq n} \\sum\\limits_{i=1}^{n} |a_{ij}|\n",
    "$$\n",
    "\n",
    ">- The subordinate matrix norm induced by  $\\|\\cdot\\|_{2}$, called spectral norm, is given by\n",
    "$$\n",
    "\\|A\\|_{2} = \\sqrt{\\rho(A^T A)}\n",
    "$$\n",
    "\n",
    "**Example** Is the Frobenius norm an induced norm?\n",
    "\n",
    "Here is a great resource for all kinds of norms in one place.\n",
    "[Comprehensive Notes on Norms](http://fourier.eng.hmc.edu/e161/lectures/algebra/node12.html#:~:text=Induced%20or%20operator%20norms%20of%20a%20matrix%20is,is%20the%20least%20upper%20bound%20of%20the%20function.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D1 and its norm: \n",
      " [[ 1  1]\n",
      " [ 1 -1]]\n",
      "2.0\n",
      "D2 and its norm: \n",
      " [[ 1  2 -1]\n",
      " [ 3  4 -6]]\n",
      "Frobeniu norm of D2: 8.18535277187245\n",
      "One norm of D2: 7.0\n",
      "Inf norm of D2: 13.0\n",
      "Spectral norm of D2: 8.113588991356071\n"
     ]
    }
   ],
   "source": [
    "# NORM : Euclidean, Frobenius\n",
    "\n",
    "D1 = np.array([[1,1],[1,-1]])\n",
    "print (\"D1 and its norm: \\n\", D1)\n",
    "print (np.linalg.norm(D1))\n",
    "\n",
    "D2 = np.array([[1,2, -1],[3,4, -6]])\n",
    "print (\"D2 and its norm: \\n\", D2)\n",
    "print (\"Frobeniu norm of D2:\",np.linalg.norm(D2,ord='fro'))\n",
    "print (\"One norm of D2:\",np.linalg.norm(D2,ord=1))\n",
    "print (\"Inf norm of D2:\",np.linalg.norm(D2,ord=np.inf))\n",
    "print (\"Spectral norm of D2:\",np.linalg.norm(D2,ord=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Special Matrices\n",
    "***\n",
    "- Symmetric ans Skew-symmetric Matrics\n",
    "- Upper and Lower Triangular Matrices\n",
    "- Banded Matrices\n",
    "- Orthogonal and Unitary Matrices\n",
    "- Positive definite, positive semidefinite matrices\n",
    "- Negative definite, negative semidefinite matrices\n",
    "- Indefinite Matrices\n",
    "- Permutation Matrix\n",
    "- Diagonally Dominant Matrices\n",
    "- Nonnegative Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Orthogonal Matrices\n",
    "A square matrix, $Q \\in \\mathbb{R}^{n \\times n}$, is called orthogonal if it satisfies the following \n",
    "$$\n",
    "Q^TQ = I_n, \\quad \\textrm{and} \\quad Q Q^T = I_n\n",
    "$$\n",
    "where $I_n$ is the identity matrix of order $n$-by-$n$.\n",
    "> - If Q is orthogonal then $Q^{-1} = Q^T$\n",
    "> - Multiplication by an orthogonal matrix preserves the angle between two vectors.\n",
    "> - As a linear transformation, an orthogonal matrix either rotates or reflects a vector, or does a combination of both.\n",
    "> - Multiplication by an orthogonal matrix preserves length ($l_2$ norm).\n",
    "> - Determinant of an orthogonal matrix is either +1 or -1.\n",
    "> - Eigenvalues of an orthogonal matrix are of unit magnitude."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Symmetric Positive Definite Matrices\n",
    "\n",
    "A symmetric matrix $A \\in \\mathbb{R}^{n \\times n}$ is...\n",
    "> - positive definite if for every $0 \\neq x\\in \\mathbb{R}^{n} $, we have $x^t A x > 0$. \n",
    "\n",
    "> -  positive semi-definite if for every $0 \\neq x\\in \\mathbb{R}^{n} $, we have $x^t A x \\geq 0$.\n",
    "\n",
    "> - negative definite if for every $0 \\neq x\\in \\mathbb{R}^{n} $, we have $x^t A x < 0$.\n",
    "\n",
    "> - negative semi-definite if for every $0 \\neq x\\in \\mathbb{R}^{n} $, we have $x^t A x \\leq 0$.\n",
    "\n",
    "If a square matrix is neither positive semidefinite nor negative semidefinite, it is called an indefintie matrix.\n",
    "\n",
    "**Test for Positive Definite Matrices**: A symmetric matrix $A$ is positive definite if and only if each of its leading principal minors are positive.\n",
    "    \n",
    "**Fact**: When $A$ is positive definite, Gaussian elimination without row-interchanges could be performed  for solving $Ax = b$ where all pivot elements are positive. \n",
    "\n",
    "**Cholesky Factorization**: Positive definite matrices could be factorized as $A = L L^t = \\tilde{L} D \\tilde{L}^t$. where $L$ is a lower triangular matrix and $\\tilde{L}$ is a unit lower triangular matrix.\n",
    "\n",
    "**Properties**\n",
    "> - All the eigenvaues of a real symmetric positive defintie matrix are positive.\n",
    "\n",
    "> - If all the eigenvalues of a real sysmmetric matrix are positive, then it is a positive defintie matrix.\n",
    "\n",
    "> - A real square matrix $A$ is positive semidefintie if and only if there exists a real matrix $M$ such that $A = M^T M$. Invertibility of $M$ is required for positive definiteness.\n",
    "\n",
    "> - A real square matrix $A$ is positive semidefinite if and inly if there exists a positive semidefinite matrix $B$ such that $A = BB$. This matrix $B$ is called square root of $A$ and is unique."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
