{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 584 Assignment 4 -- Sequence to Sequence Models\n",
    "\n",
    "#### Name: Aidan Fischer\n",
    "#### Stevens ID: 10447681"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this assignment, you are required to follow the steps below:\n",
    "1. Review the lecture slides.\n",
    "2. Implement the seq2seq (translation) model.\n",
    "\n",
    "**Before you start**\n",
    "- Please read the code very carefully.\n",
    "- Install these packages using the following command.\n",
    "```console\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "- It's better to train the Tensorflow model with GPU and CUDA. If they are not available on your local machine, please consider Google CoLab. You can check `CoLab.md` in this assignments.\n",
    "- You are **NOT** allowed to use other packages unless otherwise specified.\n",
    "- You are **ONLY** allowed to edit the code between `# Start your code here` and `# End` for each block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "def print_line(*args):\n",
    "    \"\"\" Inline print and go to the begining of line\n",
    "    \"\"\"\n",
    "    args1 = [str(arg) for arg in args]\n",
    "    str_ = ' '.join(args1)\n",
    "    print('\\r' + str_, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# If you are going to use GPU, make sure the GPU in in the output\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Union, Dict\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data preparation (5 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Load and describe data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we use the [iwslt2017](https://huggingface.co/datasets/iwslt2017) dataset. More specifically, this translation task is from French to English: fr-en."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aidan/.pyenv/versions/3.9.19/lib/python3.9/site-packages/datasets/load.py:2524: FutureWarning: 'ignore_verifications' was deprecated in favor of 'verification_mode' in version 2.9.1 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'verification_mode=no_checks' instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "# The load_dataset function is provided by the huggingface datasets\n",
    "# https://huggingface.co/docs/datasets/index\n",
    "\n",
    "\n",
    "dataset_path = os.path.join('a4-data', 'dataset')\n",
    "dataset = load_dataset('iwslt2017', 'iwslt2017-en-fr', cache_dir=dataset_path, ignore_verifications=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first print some basic statistics of this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['translation'],\n",
      "        num_rows: 232825\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['translation'],\n",
      "        num_rows: 8597\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['translation'],\n",
      "        num_rows: 890\n",
      "    })\n",
      "})\n",
      "232825 890 8597\n"
     ]
    }
   ],
   "source": [
    "print(dataset)\n",
    "print(len(dataset['train']['translation']), len(dataset['validation']['translation']), len(dataset['test']['translation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'en': \"Thank you so much, Chris. And it's truly a great honor to have the opportunity to come to this stage twice; I'm extremely grateful.\", 'fr': \"Merci beaucoup, Chris. C'est vraiment un honneur de pouvoir venir sur cette scène une deuxième fois. Je suis très reconnaissant.\"}\n"
     ]
    }
   ],
   "source": [
    "print(dataset['train']['translation'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "# The tokenizer is provided by the huggingface tokenizers\n",
    "# https://huggingface.co/docs/tokenizers/index\n",
    "# Here, I already pretrained a BPE tokenizer and you can simply load the json\n",
    "# The token numbers of both English and French are 10,000\n",
    "# All tokens should be lower-case.\n",
    "\n",
    "\n",
    "en_tokenizer = Tokenizer.from_file('a4-data/en_tokenizer.json')\n",
    "fr_tokenizer = Tokenizer.from_file('a4-data/fr_tokenizer.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 122, 279, 4987, 17, 1]\n",
      "['<s>', 'Ġi', 'Ġlike', 'Ġsports', '.', '</s>']\n"
     ]
    }
   ],
   "source": [
    "encoding = en_tokenizer.encode(\"i like sports.\")\n",
    "print(encoding.ids)\n",
    "print(encoding.tokens)\n",
    "# >>> [0, 122, 279, 4987, 17, 1] \n",
    "# >>> ['<s>', 'Ġi', 'Ġlike', 'Ġsports', '.', '</s>']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract English and French sentences for training, validation, and test sets.\n",
    "\n",
    "Note: Every sentence is lower-case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "train_en_sentences, train_fr_sentences = zip(*[(pair['en'].lower(), pair['fr'].lower()) for pair in dataset['train']['translation']])\n",
    "valid_en_sentences, valid_fr_sentences = zip(*[(pair['en'].lower(), pair['fr'].lower()) for pair in dataset['validation']['translation']])\n",
    "test_en_sentences, test_fr_sentences = zip(*[(pair['en'].lower(), pair['fr'].lower()) for pair in dataset['test']['translation']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Encode data (5 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def encode(tokenizer: 'Tokenizer', sentences: List[str]) -> List[List[int]]:\n",
    "    \"\"\" Encode the sentences with the pretrained tokenizer.\n",
    "        You can directly call `tokenizer.encode()` to encode the sentences.\n",
    "        It will automatically add the <s> and </s> token.\n",
    "        \n",
    "        Note: Please be carefull with the return value of the encode function.\n",
    "    \n",
    "    Args:\n",
    "        tokenizer: A pretrained en/fr tokenizer\n",
    "        sentences: A list of strings\n",
    "    Return:\n",
    "        sent_token_ids: A list of token ids\n",
    "    \"\"\"\n",
    "    sent_token_ids = []\n",
    "    n = len(sentences)\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        if i % 100 == 0 or i == n - 1:\n",
    "            print_line('Encoding with Tokenizer:', (i + 1), '/', n)\n",
    "        # Start your code here\n",
    "        # Encode a sentence, and add that list to sent_token_ids\n",
    "        sent_token_ids.append(tokenizer.encode(sentence).ids)\n",
    "        # End\n",
    "    print_line('\\n')\n",
    "    return sent_token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en\n",
      "Encoding with Tokenizer: 232825 / 232825\n",
      "Encoding with Tokenizer: 890 / 890\n",
      "Encoding with Tokenizer: 8597 / 8597\n",
      "fr\n",
      "Encoding with Tokenizer: 232825 / 232825\n",
      "Encoding with Tokenizer: 890 / 890\n",
      "Encoding with Tokenizer: 8597 / 8597\n"
     ]
    }
   ],
   "source": [
    "print('en')\n",
    "train_en = encode(en_tokenizer, train_en_sentences)\n",
    "valid_en = encode(en_tokenizer, valid_en_sentences)\n",
    "test_en = encode(en_tokenizer, test_en_sentences)\n",
    "print('fr')\n",
    "train_fr = encode(fr_tokenizer, train_fr_sentences)\n",
    "valid_fr = encode(fr_tokenizer, valid_fr_sentences)\n",
    "test_fr = encode(fr_tokenizer, test_fr_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check your implementation with an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'en': \"Thank you so much, Chris. And it's truly a great honor to have the opportunity to come to this stage twice; I'm extremely grateful.\", 'fr': \"Merci beaucoup, Chris. C'est vraiment un honneur de pouvoir venir sur cette scène une deuxième fois. Je suis très reconnaissant.\"}\n",
      "[0, 658, 162, 188, 494, 15, 2843, 17, 138, 165, 178, 2775, 121, 630, 4502, 140, 222, 124, 1930, 140, 625, 140, 185, 2122, 3446, 30, 122, 400, 2576, 5818, 17, 1] [0, 763, 478, 15, 3016, 17, 145, 10, 178, 487, 169, 8981, 152, 1038, 2055, 266, 323, 2425, 220, 1760, 586, 17, 214, 459, 378, 9952, 17, 1]\n",
      " thank you so much, chris. and it's truly a great honor to have the opportunity to come to this stage twice; i'm extremely grateful.  merci beaucoup, chris. c'est vraiment un honneur de pouvoir venir sur cette scène une deuxième fois. je suis très reconnaissant.\n"
     ]
    }
   ],
   "source": [
    "print(dataset['train']['translation'][0])\n",
    "print(train_en[0], train_fr[0])\n",
    "print(en_tokenizer.decode(train_en[0]), fr_tokenizer.decode(train_fr[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sequence to sequence model (40 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Encoder (10 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, GRU, Dense, Embedding, Dropout, GRUCell\n",
    "from tensorflow.keras.initializers import GlorotUniform\n",
    "\n",
    "\n",
    "class Encoder(Model):\n",
    "    def __init__(self, vocab_size: int, embedding_size: int, units: int):\n",
    "        \"\"\" The encoder model for the src sentences.\n",
    "            It contains an embedding part and a GRU part.\n",
    "        \n",
    "        Args:\n",
    "            vocab_size: The src vocabulary size\n",
    "            embedding_size: The embedding size for the embedding layer\n",
    "            units: Number of hidden units in the RNN (GRU) layer\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # Start your code here\n",
    "        # Note: Please know what the decoder needs from encoder. This determines the parameters of the GRU layer\n",
    "        # Determine whether the model is in training mode.\n",
    "        self.training = None\n",
    "        # Set up the required layers. \n",
    "        self.embedding = Embedding(vocab_size, embedding_size)\n",
    "        self.GRU = GRU(units, return_sequences = True, return_state = True)\n",
    "        # End\n",
    "\n",
    "    def call(self, src_ids, src_mask):\n",
    "        \"\"\" Encoder forward\n",
    "        Args:\n",
    "            src_ids: Tensor, (batch_size x max_len), the token ids of input sentences in a batch\n",
    "            src_mask: Tensor, (batch_size x max_len), the mask of the src input. True value in the mask means this timestep is valid, otherwise this timestep is ignored\n",
    "        Returns:\n",
    "            enc_output: Tensor, (batch_size x max_len x units), the output of GRU for all timesteps\n",
    "            final_state: Tensor, (batch_size x units), the state of the final valid timestep\n",
    "        \"\"\"\n",
    "        # Start your code here\n",
    "        # Step 1. Retrieve embedding\n",
    "        #      2. GRU\n",
    "        # Please refer to the calling arguments of GRU: https://www.tensorflow.org/api_docs/python/tf/keras/layers/GRU#call-arguments\n",
    "        # Pass the input tokens through the embedding layer and then apply the GRU layer. Return the output of the GRU layer.\n",
    "        emb_outputs = self.embedding(src_ids)\n",
    "        enc_outputs, final_state = self.GRU(inputs = emb_outputs, mask = src_mask, training = self.training)\n",
    "        # End\n",
    "        return enc_outputs, final_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Decoder (15 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder with attention layer\n",
    "\n",
    "class Decoder(Model):\n",
    "    def __init__(self, vocab_size: int, embedding_size: int, units: int, dropout_rate: float):\n",
    "        \"\"\" The decoder model for the tgt sentences.\n",
    "            It contains an embedding part, a GRU part, a dropout part, and a classifier part.\n",
    "            \n",
    "        Args:\n",
    "            vocab_size: The tgt vocabulary size\n",
    "            embedding_size: The embedding size for the embedding layer\n",
    "            units: Number of hidden units in the RNN (GRU) layer\n",
    "            dropout_rate: The classifier has a (units x vocab_size) weight. This is a large weight matrix. We apply a dropout layer to avoid overfitting.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # Start your code here\n",
    "        # Note: 1. Please correctly set the parameter of GRU\n",
    "        #       2. No softmax here because we will need the sequence to sequence loss later\n",
    "        # Define the required layers\n",
    "        self.embedding = Embedding(vocab_size, embedding_size)\n",
    "        self.GRU = GRU(units, return_sequences = True, return_state = True)\n",
    "        self.dropout = Dropout(dropout_rate)\n",
    "        self.dense = Dense(vocab_size)\n",
    "        self.training = None\n",
    "        # End\n",
    "\n",
    "    def call(self, tgt_ids, initial_state, tgt_mask):\n",
    "        \"\"\" Decoder forward.\n",
    "            It is called by decoder(tgt_ids=..., initial_state=..., tgt_mask=...)\n",
    "\n",
    "        Args:\n",
    "            tgt_ids: Tensor, (batch_size x max_len), the token ids of input sentences in a batch\n",
    "            initial_state: Tensor, (batch_size x units), the state of the final valid timestep from the encoder\n",
    "            tgt_mask: Tensor, (batch_size x max_len), the mask of the tgt input. True value in the mask means this timestep is valid, otherwise this timestep is ignored\n",
    "        Return:\n",
    "            dec_outputs: Tensor, (batch_size x max_len x vocab_size), the output of GRU for all timesteps\n",
    "        \"\"\"\n",
    "        # Start your code here\n",
    "        # Step 1. Retrieve embedding\n",
    "        #      2. GRU\n",
    "        #      3. Apply dropout to the GRU output\n",
    "        #      4. Classifier\n",
    "        # Note: Please refer to the calling arguments of GRU: https://www.tensorflow.org/api_docs/python/tf/keras/layers/GRU#call-arguments\n",
    "        # Pass information through the model's layers. \n",
    "        emb_outputs = self.embedding(tgt_ids)\n",
    "        gru_outputs, final_state = self.GRU(inputs = emb_outputs, mask = tgt_mask, initial_state = initial_state, training = self.training)\n",
    "        dropout_outputs = self.dropout(gru_outputs, training = self.training)\n",
    "        dec_outputs = self.dense(dropout_outputs)\n",
    "        # End\n",
    "        return dec_outputs\n",
    "\n",
    "    def predict(self, tgt_ids, initial_state):\n",
    "        \"\"\" Decoder prediction.\n",
    "            This is a step in recursive prediction. We use the previous prediction and state to predict current token.\n",
    "            Note that we only need to use the gru_cell instead of GRU becasue we only need to calculate one timestep.\n",
    "            \n",
    "        Args:\n",
    "            tgt_ids: Tensor, (batch_size, ) -> (1, ), the token id of the current timestep in the current sentence.\n",
    "            initial_state: Tensor, (batch_size x units) -> (1 x units), the state of the final valid timestep from the encoder or the previous hidden state in prediction.\n",
    "        Return:\n",
    "            dec_outputs: Tensor, (batch_size x vocab_size) -> (1 x vocab_size), the output of GRU for this timestep.\n",
    "            state: Tensor, (batch_size x units) -> (1 x units), the state of this timestep.\n",
    "        \"\"\"\n",
    "        gru_cell = self.GRU.cell\n",
    "        # Start your code here\n",
    "        # Step 1. Retrieve embedding\n",
    "        #      2. GRU Cell, see https://www.tensorflow.org/api_docs/python/tf/keras/layers/GRUCell#call-arguments\n",
    "        #      3. Classifier (No dropout)\n",
    "        emb_outputs = self.embedding(tgt_ids)\n",
    "        gru_outputs, state = gru_cell(inputs = emb_outputs, states = initial_state, training = self.training)\n",
    "        dec_outputs = self.dense(gru_outputs)\n",
    "        # End\n",
    "        return dec_outputs, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d1e99e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Attention, Concatenate\n",
    "class AttentionDecoder(Model):\n",
    "    def __init__(self, vocab_size: int, embedding_size: int, units: int, dropout_rate: float):\n",
    "        \"\"\" The attention decoder model for the tgt sentences.\n",
    "            It contains an embedding part, a GRU part, an attention part, a dropout part, and a classifier part.\n",
    "            \n",
    "        Args:\n",
    "            vocab_size: The tgt vocabulary size\n",
    "            embedding_size: The embedding size for the embedding layer\n",
    "            units: Number of hidden units in the RNN (GRU) layer\n",
    "            dropout_rate: The classifier has a (units x vocab_size) weight. This is a large weight matrix. We apply a dropout layer to avoid overfitting.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # Start your code here\n",
    "        # Note: 1. Please correctly set the parameter of GRU\n",
    "        #       2. No softmax here because we will need the sequence to sequence loss later\n",
    "        # Set up the required layers for a decoder, with a new attention layer and concatenation layer\n",
    "        self.embedding = Embedding(vocab_size, embedding_size)\n",
    "        self.GRU = GRU(units, return_sequences = True, return_state = True)\n",
    "        self.attention = Attention()\n",
    "        self.dropout = Dropout(dropout_rate)\n",
    "        self.dense = Dense(vocab_size)\n",
    "        self.concat = Concatenate()\n",
    "        self.training = None\n",
    "        # End\n",
    "\n",
    "    def call(self, tgt_ids, initial_state, tgt_mask, enc_outputs):\n",
    "        \"\"\" Decoder forward.\n",
    "            It is called by decoder(tgt_ids=..., initial_state=..., tgt_mask=...)\n",
    "\n",
    "        Args:\n",
    "            tgt_ids: Tensor, (batch_size x max_len), the token ids of input sentences in a batch\n",
    "            initial_state: Tensor, (batch_size x units), the state of the final valid timestep from the encoder\n",
    "            tgt_mask: Tensor, (batch_size x max_len), the mask of the tgt input. True value in the mask means this timestep is valid, otherwise this timestep is ignored\n",
    "            enc_outputs: Tensor, (batch_size x max_len x units), the output of the encoder GRU for all timesteps. Used as the values in the attention layer\n",
    "        Return:\n",
    "            dec_outputs: Tensor, (batch_size x max_len x vocab_size), the output of GRU for all timesteps\n",
    "        \"\"\"\n",
    "        # Start your code here\n",
    "        # Step 1. Retrieve embedding\n",
    "        #      2. GRU\n",
    "        #      3. Attention layer. Decoder attends to encoder output\n",
    "        #      4. Concatenate GRU and Attention outputs\n",
    "        #      5. Apply dropout\n",
    "        #      6. Classifier\n",
    "        # Note: Please refer to the calling arguments of GRU: https://www.tensorflow.org/api_docs/python/tf/keras/layers/GRU#call-arguments\n",
    "        # Same as decoder, but GRU output is passed through an attention layer as well, \n",
    "        # where the query is the output of the GRU layer and the values are the encoder outputs\n",
    "        emb_outputs = self.embedding(tgt_ids)\n",
    "        gru_outputs, final_state = self.GRU(inputs = emb_outputs, mask = tgt_mask, initial_state = initial_state, training = self.training)\n",
    "        attention_outputs = self.attention([gru_outputs, enc_outputs], use_causal_mask = False, training = self.training)\n",
    "        # Concatenate the GRU and attention outputs to form y_hats\n",
    "        concat_outputs = self.concat([gru_outputs, attention_outputs])\n",
    "        dropout_outputs = self.dropout(concat_outputs, training = self.training)\n",
    "        dec_outputs = self.dense(dropout_outputs)\n",
    "        # End\n",
    "        return dec_outputs\n",
    "\n",
    "    def predict(self, tgt_ids, initial_state, enc_outputs):\n",
    "        \"\"\" Decoder prediction.\n",
    "            This is a step in recursive prediction. We use the previous prediction and state to predict current token.\n",
    "            Note that we only need to use the gru_cell instead of GRU becasue we only need to calculate one timestep.\n",
    "            \n",
    "        Args:\n",
    "            tgt_ids: Tensor, (batch_size, ) -> (1, ), the token id of the current timestep in the current sentence.\n",
    "            initial_state: Tensor, (batch_size x units) -> (1 x units), the state of the final valid timestep from the encoder or the previous hidden state in prediction.\n",
    "            enc_outputs: Tensor, (batch_size x max_len x units), the output of the encoder GRU for all timesteps. Used as the values in the attention layer\n",
    "        Return:\n",
    "            dec_outputs: Tensor, (batch_size x vocab_size) -> (1 x vocab_size), the output of GRU for this timestep.\n",
    "            state: Tensor, (batch_size x units) -> (1 x units), the state of this timestep.\n",
    "        \"\"\"\n",
    "        gru_cell = self.GRU.cell\n",
    "        # Start your code here\n",
    "        # Step 1. Retrieve embedding\n",
    "        #      2. GRU Cell, see https://www.tensorflow.org/api_docs/python/tf/keras/layers/GRUCell#call-arguments\n",
    "        #      3. Attention\n",
    "        #      4. Concat\n",
    "        #      5. Classifier (No dropout)\n",
    "        # Same as call except performing one step as in the normal decoder. \n",
    "        emb_outputs = self.embedding(tgt_ids)\n",
    "        gru_outputs, state = gru_cell(inputs = emb_outputs, states = initial_state, training = self.training)\n",
    "        attention_outputs = self.attention([gru_outputs, enc_outputs], use_causal_mask = False, training = self.training)\n",
    "        # Need expand dims here cause gru_outputs doesn't have a max_len dimension here.\n",
    "        concat_outputs = self.concat([tf.expand_dims(gru_outputs, axis = 0), attention_outputs])\n",
    "        dec_outputs = self.dense(concat_outputs)\n",
    "        # End\n",
    "        return dec_outputs, state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5d2a4a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Seq2seq (10 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2seq(Model):\n",
    "    def __init__(self, src_vocab_size: int, tgt_vocab_size: int, embedding_size: int, units: int, dropout_rate: float):\n",
    "        \"\"\" The sequence to sequence model.\n",
    "            It contains an encoder and a decoder.\n",
    "            \n",
    "        Args:\n",
    "            src_vocab_size: The src vocabulary size\n",
    "            tgt_vocab_size: The tgt vocabulary size\n",
    "            embedding_size: The embedding size for the embedding layer\n",
    "            units: Number of hidden units in the RNN (GRU) layer\n",
    "            dropout_rate: The dropout rate used in the decoder.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # Start your code here\n",
    "        # Set up the encoder and decoder models\n",
    "        self.encoder = Encoder(src_vocab_size, embedding_size, units)\n",
    "        self.decoder = Decoder(tgt_vocab_size, embedding_size, units, dropout_rate)\n",
    "        # End\n",
    "        \n",
    "    def set_training(self, training):\n",
    "        # Set the training mode used for the Seq2Seq model's encoder and decoder\n",
    "        self.decoder.training = training\n",
    "        self.encoder.training = training\n",
    "\n",
    "    def call(self, src_ids, src_seq_lens, tgt_ids, tgt_seq_lens):\n",
    "        \"\"\" Seq2seq forward (for the loss calculation in training/validation only).\n",
    "            It is called by model(src_ids=..., src_seq_lens=..., tgt_ids=..., tgt_seq_lens=)\n",
    "            Note: In prediction, we will also need to set `training=False`.\n",
    "\n",
    "        Args:\n",
    "            src_ids: Tensor, (batch_size x max_len), the token ids of src sentences in a batch\n",
    "            src_seq_lens: Tensor, (batch_size, ), the length of src sentences in a batch\n",
    "            tgt_ids: Tensor, (batch_size x max_len), the token ids of tgt sentences in a batch\n",
    "            tgt_seq_lens: Tensor, (batch_size, ), the length of src sentences in a batch\n",
    "        Returns:\n",
    "            dec_outputs: Tensor, (batch_size x max_len x units), the decoder predictions\n",
    "        \"\"\"\n",
    "        # Start your code here\n",
    "        # Step 1. build mask for src and tgt\n",
    "        #      2. encoder forward\n",
    "        #      3. decoder forward\n",
    "        # Create the masks from the provided lengths, then call the encoder and decoder\n",
    "        src_mask = tf.sequence_mask(src_seq_lens)\n",
    "        tgt_mask = tf.sequence_mask(tgt_seq_lens)\n",
    "        enc_outputs, enc_final_state = self.encoder(src_ids, src_mask)\n",
    "        dec_outputs = self.decoder(tgt_ids, enc_final_state, tgt_mask)\n",
    "        # End\n",
    "        return dec_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "22f2b439",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2seqAttention(Model):\n",
    "    def __init__(self, src_vocab_size: int, tgt_vocab_size: int, embedding_size: int, units: int, dropout_rate: float):\n",
    "        \"\"\" The sequence to sequence + attention model.\n",
    "            It contains an encoder and a decoder with attention.\n",
    "            \n",
    "        Args:\n",
    "            src_vocab_size: The src vocabulary size\n",
    "            tgt_vocab_size: The tgt vocabulary size\n",
    "            embedding_size: The embedding size for the embedding layer\n",
    "            units: Number of hidden units in the RNN (GRU) layer\n",
    "            dropout_rate: The dropout rate used in the decoder.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # Start your code here\n",
    "        # Same as base model, but use AttentionDecoder instead\n",
    "        self.encoder = Encoder(src_vocab_size, embedding_size, units)\n",
    "        self.decoder = AttentionDecoder(tgt_vocab_size, embedding_size, units, dropout_rate)\n",
    "        # End\n",
    "        \n",
    "    def set_training(self, training):\n",
    "        self.decoder.training = training\n",
    "        self.encoder.training = training\n",
    "\n",
    "    def call(self, src_ids, src_seq_lens, tgt_ids, tgt_seq_lens):\n",
    "        \"\"\" Seq2seq forward (for the loss calculation in training/validation only).\n",
    "            It is called by model(src_ids=..., src_seq_lens=..., tgt_ids=..., tgt_seq_lens=)\n",
    "            Note: In prediction, we will also need to set `training=False`.\n",
    "\n",
    "        Args:\n",
    "            src_ids: Tensor, (batch_size x max_len), the token ids of src sentences in a batch\n",
    "            src_seq_lens: Tensor, (batch_size, ), the length of src sentences in a batch\n",
    "            tgt_ids: Tensor, (batch_size x max_len), the token ids of tgt sentences in a batch\n",
    "            tgt_seq_lens: Tensor, (batch_size, ), the length of src sentences in a batch\n",
    "        Returns:\n",
    "            dec_outputs: Tensor, (batch_size x max_len x units), the decoder predictions\n",
    "        \"\"\"\n",
    "        # Start your code here\n",
    "        # Step 1. build mask for src and tgt\n",
    "        #      2. encoder forward\n",
    "        #      3. decoder forward\n",
    "        src_mask = tf.sequence_mask(src_seq_lens)\n",
    "        tgt_mask = tf.sequence_mask(tgt_seq_lens)\n",
    "        enc_outputs, enc_final_state = self.encoder(src_ids, src_mask)\n",
    "        # This all is the same as base seq2seq, but using AttentionDecoder requires passing encoder outputs\n",
    "        dec_outputs = self.decoder(tgt_ids, enc_final_state, tgt_mask, enc_outputs)\n",
    "        # End\n",
    "        return dec_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Seq2seq loss (5 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_addons.seq2seq import sequence_loss\n",
    "\n",
    "def seq2seq_loss(logits, target, seq_lens):\n",
    "    \"\"\" Calculate the sequence to sequence loss using the sequence_loss from tensorflow\n",
    "    \n",
    "    Args:\n",
    "        logits: Tensor (batch_size x max_seq_len x vocab_size). The output of the RNN model.\n",
    "        target: Tensor (batch_size x max_seq_len). The groud-truth of words.\n",
    "        seq_lens: Tensor (batch_size, ). The real sequence length before padding.\n",
    "    \"\"\"\n",
    "    loss = 0\n",
    "    # Start your code here\n",
    "    # 1. make a sequence mask (batch_size x max_seq_len) using tf.sequence_mask. This is to build a mask with 1 and 0.\n",
    "    #    Entry with 1 is the valid time step without padding. Entry with 0 is the time step with padding. We need to exclude this time step.\n",
    "    # 2. calculate the loss with sequence_loss. Carefully read the documentation of each parameter\n",
    "    seq_mask = tf.sequence_mask(seq_lens, dtype=tf.float32)\n",
    "    loss = sequence_loss(logits = logits, targets = target, weights = seq_mask, average_across_batch=False,\n",
    "                         average_across_timesteps=False, sum_over_batch=True, sum_over_timesteps=True)\n",
    "    # End\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training (50 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Pad batch (15 Points)\n",
    "\n",
    "`pad_src_batch`: 5 Points\n",
    "`pad_tgt_batch`: 10 Points\n",
    "\n",
    "Pad the batch to the equal length and make tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_src_batch(src_batch: List[List[int]], src_seq_lens: List[int], pad_val: int):\n",
    "    \"\"\" Pad the batch for src sentences.\n",
    "        Note: Do not use append/extend that can modify the input inplace.\n",
    "    \n",
    "    Args:\n",
    "        src_batch: A list of src token ids\n",
    "        src_seq_lens: A list of src lens\n",
    "        pad_val: The padding value\n",
    "        \n",
    "    Returns:\n",
    "        src_batch: Tensor, (batch_size x max_len)\n",
    "        src_seq_lens_batch: Tensor, (batch_size, )\n",
    "    \"\"\"\n",
    "    max_src_len = max(src_seq_lens)\n",
    "    # Start your code here\n",
    "    # Please refer to tf.convert_to_tensor. The dtype should be tf.int64\n",
    "    # Padding\n",
    "    padded = tf.keras.utils.pad_sequences(src_batch, maxlen = max_src_len, dtype='int64', padding='post', value = pad_val)\n",
    "    # Convert to tensor\n",
    "    src_batch = tf.convert_to_tensor(padded, dtype=tf.int64)\n",
    "    src_seq_lens_batch = tf.convert_to_tensor(src_seq_lens, dtype=tf.int64)\n",
    "    # End\n",
    "    return src_batch, src_seq_lens_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_tgt_batch(tgt_batch: List[List[int]], tgt_seq_lens: List[int], pad_val: int):\n",
    "    \"\"\" Pad the batch for tgt sentences.\n",
    "        Note: 1. Do not use append/extend that can modify the input inplace.\n",
    "              2. We need to build the x (feature) and y (label) for tgt sentences.\n",
    "                 Please understand what the feature and label are in translation.\n",
    "    \n",
    "    Args:\n",
    "        tgt_batch: A list of src token ids\n",
    "        tgt_seq_lens: A list of src lens\n",
    "        pad_val: The padding value\n",
    "        \n",
    "    Returns:\n",
    "        tgt_x_batch: Tensor, (batch_size x max_len)\n",
    "        tgt_y_batch: Tensor, (batch_size x max_len)\n",
    "        src_seq_lens_batch: Tensor, (batch_size, )\n",
    "    \"\"\"\n",
    "    tgt_x_batch, tgt_y_batch, tgt_seq_lens_batch = [], [], []\n",
    "    for sent, seq_len in zip(tgt_batch, tgt_seq_lens):\n",
    "        # Start your code here\n",
    "        # Append x, y, and seq_len\n",
    "        # X is the sentence minus the last token (the EOS token)\n",
    "        # Y is the sentence minus the first token (the SOS token)\n",
    "        tgt_x_batch.append(sent[:-1].copy())\n",
    "        tgt_y_batch.append(sent[1:].copy())\n",
    "        tgt_seq_lens_batch.append(seq_len)\n",
    "        # End\n",
    "\n",
    "    max_tgt_len = max(tgt_seq_lens_batch)\n",
    "    # Start your code here\n",
    "    # Please refer to tf.convert_to_tensor. The dtype should be tf.int64\n",
    "    # Padding\n",
    "    padded_x = tf.keras.utils.pad_sequences(tgt_x_batch, maxlen = max_tgt_len, dtype='int64', padding='post', value = pad_val)\n",
    "    padded_y = tf.keras.utils.pad_sequences(tgt_y_batch, maxlen = max_tgt_len, dtype='int64', padding='post', value = pad_val)\n",
    "    # Convert to tensor\n",
    "    tgt_x_batch = tf.convert_to_tensor(padded_x, dtype=tf.int64)\n",
    "    tgt_y_batch = tf.convert_to_tensor(padded_y, dtype=tf.int64)\n",
    "    tgt_seq_lens_batch = tf.convert_to_tensor(tgt_seq_lens_batch, dtype=tf.int64)\n",
    "    # End\n",
    "    return tgt_x_batch, tgt_y_batch, tgt_seq_lens_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_batch(src_batch: List[List[int]], src_seq_lens: List[int], tgt_batch: List[List[int]], tgt_seq_lens: List[int], pad_val: int):\n",
    "    src_batch, src_seq_lens_batch = pad_src_batch(src_batch, src_seq_lens, pad_val)\n",
    "    tgt_x_batch, tgt_y_batch, tgt_seq_lens_batch = pad_tgt_batch(tgt_batch, tgt_seq_lens, pad_val)\n",
    "    return src_batch, src_seq_lens_batch, tgt_x_batch, tgt_y_batch, tgt_seq_lens_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Batch Index Sampler (10 Points)\n",
    "\n",
    "Create a index sampler to sample data index for each batch.\n",
    "\n",
    "This is to make the sentences in each batch have similar lengths to speed up training.\n",
    "\n",
    "Example:\n",
    "```\n",
    "Assume the sentence lengths are: [5, 2, 3, 6, 2, 3, 6] and batch_size is 2.\n",
    "We can make the indices in the batches as follows:\n",
    "[1, 4] of length 2\n",
    "[2, 5] of length 3\n",
    "[0, 3] of lengths 5 and 6\n",
    "[6] of length 6\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqLenBatchSampler:\n",
    "    def __init__(self, seq_lens: List[int], batch_size: int, seed: int = 6666):\n",
    "        \"\"\" The index sampler.\n",
    "            It can be used with iteration:\n",
    "            ```\n",
    "            n_batch = len(sampler)\n",
    "            for indices in sampler:\n",
    "                ...\n",
    "            ```\n",
    "            \n",
    "            Args:\n",
    "                seq_lens: A list training sequence lengths (src)\n",
    "                batch_size: .\n",
    "                seed: .\n",
    "        \"\"\"\n",
    "        np.random.seed(seed)\n",
    "        self.seq_lens = seq_lens\n",
    "        self.batch_size = batch_size\n",
    "        self.batches = self._make_batch_index()\n",
    "\n",
    "        self.n_batch = len(self.batches)\n",
    "        self.counter = -1\n",
    "        \n",
    "    def _make_batch_index(self) -> List[List[int]]:\n",
    "        \"\"\" Build the indexes in each batch.\n",
    "\n",
    "            Return:\n",
    "                batches: A list of indices batch, e.g., [[0, 2, 8], [3, 6, 4], [5, 1, 7], ...]\n",
    "        \"\"\"\n",
    "        n = len(self.seq_lens)\n",
    "        n_batch = int(np.ceil(n / self.batch_size))\n",
    "        batches = []\n",
    "        # Start your code here\n",
    "        # Step 1. Use np.argsort to get all indices with sorted length\n",
    "        #      2. Split the indices into batches using a for loop: `for i in range(n_batch):`\n",
    "        ordered = np.argsort(self.seq_lens)\n",
    "        for i in range(n_batch):\n",
    "            batches.append(ordered[i * self.batch_size : (i + 1) * self.batch_size])\n",
    "        # End\n",
    "        return batches\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_batch\n",
    "    \n",
    "    def __item__(self, index):\n",
    "        return self.batches[index]\n",
    "    \n",
    "    def __iter__(self):\n",
    "        np.random.shuffle(self.batches)\n",
    "        self.counter = -1\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        self.counter += 1\n",
    "        if self.counter < self.n_batch:\n",
    "            return self.batches[self.counter]\n",
    "        raise StopIteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Running the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(6666)\n",
    "train_seq_lens_en = [len(en_sent) for en_sent in train_en]\n",
    "train_seq_lens_fr = [len(fr_sent) for fr_sent in train_fr]\n",
    "valid_seq_lens_en = [len(en_sent) for en_sent in valid_en]\n",
    "valid_seq_lens_fr = [len(fr_sent) for fr_sent in valid_fr]\n",
    "test_seq_lens_en = [len(en_sent) for en_sent in test_en]\n",
    "test_seq_lens_fr = [len(fr_sent) for fr_sent in test_fr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create np array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_en = np.array(train_en, dtype=object)\n",
    "train_seq_lens_en = np.array(train_seq_lens_en)\n",
    "train_fr = np.array(train_fr, dtype=object)\n",
    "train_seq_lens_fr = np.array(train_seq_lens_fr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "seed = 6666\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab_size = len(fr_tokenizer.get_vocab())\n",
    "tgt_vocab_size = len(en_tokenizer.get_vocab())\n",
    "hidden_units = 256\n",
    "embedding_dim = 128\n",
    "dropout_rate = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Seq2seq(src_vocab_size, tgt_vocab_size, embedding_dim, hidden_units, dropout_rate)\n",
    "model.set_training(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9cf51a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_model = Seq2seqAttention(src_vocab_size, tgt_vocab_size, embedding_dim, hidden_units, dropout_rate)\n",
    "attention_model.set_training(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch = 15\n",
    "batch_size = 256\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "train_batch_sampler = SeqLenBatchSampler(train_seq_lens_fr, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ef25b6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "attention_train_batch_sampler = SeqLenBatchSampler(train_seq_lens_fr, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 15 - Step 910 / 910 - train loss: 5.6260 - valid loss: 5.4835\n",
      "Epoch 2 / 15 - Step 910 / 910 - train loss: 4.4674 - valid loss: 4.7475\n",
      "Epoch 3 / 15 - Step 910 / 910 - train loss: 3.8955 - valid loss: 4.4737\n",
      "Epoch 4 / 15 - Step 910 / 910 - train loss: 3.5743 - valid loss: 4.3011\n",
      "Epoch 5 / 15 - Step 910 / 910 - train loss: 3.3569 - valid loss: 4.1839\n",
      "Epoch 6 / 15 - Step 910 / 910 - train loss: 3.1933 - valid loss: 4.1135\n",
      "Epoch 7 / 15 - Step 910 / 910 - train loss: 3.0648 - valid loss: 4.0503\n",
      "Epoch 8 / 15 - Step 910 / 910 - train loss: 2.9535 - valid loss: 4.0185\n",
      "Epoch 9 / 15 - Step 910 / 910 - train loss: 2.8594 - valid loss: 3.9759\n",
      "Epoch 10 / 15 - Step 910 / 910 - train loss: 2.7765 - valid loss: 3.9532\n",
      "Epoch 11 / 15 - Step 910 / 910 - train loss: 2.7055 - valid loss: 3.9290\n",
      "Epoch 12 / 15 - Step 910 / 910 - train loss: 2.6423 - valid loss: 3.9189\n",
      "Epoch 13 / 15 - Step 910 / 910 - train loss: 2.5858 - valid loss: 3.9292\n",
      "Epoch 14 / 15 - Step 910 / 910 - train loss: 2.5344 - valid loss: 3.9152\n",
      "Epoch 15 / 15 - Step 910 / 910 - train loss: 2.4884 - valid loss: 3.9026\n"
     ]
    }
   ],
   "source": [
    "n_training_samples = len(train_fr)\n",
    "n_valid_batch = int(np.ceil(len(valid_fr) / batch_size))\n",
    "pad_token_id = fr_tokenizer.token_to_id('<pad>')\n",
    "train_losses, valid_losses = [], []\n",
    "for epoch in range(num_epoch):\n",
    "    epoch_loss = 0.0\n",
    "    for batch_idx, data_index in enumerate(train_batch_sampler):\n",
    "        src_batch, src_seq_lens = train_fr[data_index], train_seq_lens_fr[data_index]\n",
    "        tgt_batch, tgt_seq_lens = train_en[data_index], train_seq_lens_en[data_index]\n",
    "        real_batch_size = len(src_batch)\n",
    "        (src_batch, src_seq_lens_batch,\n",
    "         tgt_x_batch, tgt_y_batch, tgt_seq_lens_batch) = pad_batch(src_batch, src_seq_lens,\n",
    "                                                                   tgt_batch, tgt_seq_lens,\n",
    "                                                                   pad_val=pad_token_id)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            output = model(src_batch, src_seq_lens_batch, tgt_x_batch, tgt_seq_lens_batch)\n",
    "            loss = seq2seq_loss(output, tgt_y_batch, tgt_seq_lens_batch)\n",
    "\n",
    "        print_line(f'Epoch {epoch + 1} / {num_epoch} - Step {batch_idx + 1} / {len(train_batch_sampler)} - loss: {loss:.4f}')\n",
    "\n",
    "        trainable_vars = model.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "\n",
    "        # Update weights\n",
    "        optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        epoch_loss += loss * real_batch_size\n",
    "\n",
    "    valid_loss = 0.0\n",
    "    for batch_idx in range(n_valid_batch):\n",
    "        start = batch_idx * batch_size\n",
    "        end = start + batch_size\n",
    "        src_batch, src_seq_lens = valid_fr[start:end], valid_seq_lens_fr[start:end]\n",
    "        tgt_batch, tgt_seq_lens = valid_en[start:end], valid_seq_lens_en[start:end]\n",
    "        real_batch_size = len(src_batch)\n",
    "        (src_batch, src_seq_lens_batch,\n",
    "         tgt_x_batch, tgt_y_batch, tgt_seq_lens_batch) = pad_batch(src_batch, src_seq_lens,\n",
    "                                                                   tgt_batch, tgt_seq_lens,\n",
    "                                                                   pad_val=pad_token_id)\n",
    "        output = model(src_batch, src_seq_lens_batch, tgt_x_batch, tgt_seq_lens_batch, training=False)\n",
    "        loss = seq2seq_loss(output, tgt_y_batch, tgt_seq_lens_batch)\n",
    "\n",
    "        if batch_idx % 1 == 0 or batch_idx == len(valid_en) - 1:\n",
    "            print_line(f'Epoch {epoch + 1} / {num_epoch} - Step {batch_idx + 1} / {n_valid_batch} - loss: {loss:.4f}')\n",
    "\n",
    "        valid_loss += loss * real_batch_size\n",
    "    train_epoch_loss = epoch_loss / n_training_samples\n",
    "    valid_epoch_loss = valid_loss / len(valid_en)\n",
    "    train_losses.append(train_epoch_loss)\n",
    "    valid_losses.append(valid_epoch_loss)\n",
    "    print(f'\\rEpoch {epoch + 1} / {num_epoch} - Step {len(train_batch_sampler)} / {len(train_batch_sampler)} - train loss: {train_epoch_loss:.4f} - valid loss: {valid_epoch_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a62b372f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 15 - Step 910 / 910 - train loss: 4.9309 - valid loss: 4.9111\n",
      "Epoch 2 / 15 - Step 910 / 910 - train loss: 3.9595 - valid loss: 4.3504\n",
      "Epoch 3 / 15 - Step 910 / 910 - train loss: 3.1371 - valid loss: 3.7715\n",
      "Epoch 4 / 15 - Step 910 / 910 - train loss: 2.6028 - valid loss: 3.4797\n",
      "Epoch 5 / 15 - Step 910 / 910 - train loss: 2.3036 - valid loss: 3.3335\n",
      "Epoch 6 / 15 - Step 910 / 910 - train loss: 2.1162 - valid loss: 3.2452\n",
      "Epoch 7 / 15 - Step 910 / 910 - train loss: 1.9818 - valid loss: 3.1922\n",
      "Epoch 8 / 15 - Step 910 / 910 - train loss: 1.8792 - valid loss: 3.1662\n",
      "Epoch 9 / 15 - Step 910 / 910 - train loss: 1.7937 - valid loss: 3.1542\n",
      "Epoch 10 / 15 - Step 910 / 910 - train loss: 1.7235 - valid loss: 3.1685\n",
      "Epoch 11 / 15 - Step 910 / 910 - train loss: 1.6647 - valid loss: 3.1519\n",
      "Epoch 12 / 15 - Step 910 / 910 - train loss: 1.6078 - valid loss: 3.1478\n",
      "Epoch 13 / 15 - Step 910 / 910 - train loss: 1.5581 - valid loss: 3.1449\n",
      "Epoch 14 / 15 - Step 910 / 910 - train loss: 1.5157 - valid loss: 3.1481\n",
      "Epoch 15 / 15 - Step 910 / 910 - train loss: 1.4761 - valid loss: 3.1847\n"
     ]
    }
   ],
   "source": [
    "n_training_samples = len(train_fr)\n",
    "n_valid_batch = int(np.ceil(len(valid_fr) / batch_size))\n",
    "pad_token_id = fr_tokenizer.token_to_id('<pad>')\n",
    "attention_train_losses, attention_valid_losses = [], []\n",
    "for epoch in range(num_epoch):\n",
    "    epoch_loss = 0.0\n",
    "    for batch_idx, data_index in enumerate(attention_train_batch_sampler):\n",
    "        src_batch, src_seq_lens = train_fr[data_index], train_seq_lens_fr[data_index]\n",
    "        tgt_batch, tgt_seq_lens = train_en[data_index], train_seq_lens_en[data_index]\n",
    "        real_batch_size = len(src_batch)\n",
    "        (src_batch, src_seq_lens_batch,\n",
    "         tgt_x_batch, tgt_y_batch, tgt_seq_lens_batch) = pad_batch(src_batch, src_seq_lens,\n",
    "                                                                   tgt_batch, tgt_seq_lens,\n",
    "                                                                   pad_val=pad_token_id)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            output = attention_model(src_batch, src_seq_lens_batch, tgt_x_batch, tgt_seq_lens_batch)\n",
    "            loss = seq2seq_loss(output, tgt_y_batch, tgt_seq_lens_batch)\n",
    "\n",
    "        print_line(f'Epoch {epoch + 1} / {num_epoch} - Step {batch_idx + 1} / {len(train_batch_sampler)} - loss: {loss:.4f}')\n",
    "\n",
    "        trainable_vars = attention_model.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "\n",
    "        # Update weights\n",
    "        attention_optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        epoch_loss += loss * real_batch_size\n",
    "\n",
    "    valid_loss = 0.0\n",
    "    for batch_idx in range(n_valid_batch):\n",
    "        start = batch_idx * batch_size\n",
    "        end = start + batch_size\n",
    "        src_batch, src_seq_lens = valid_fr[start:end], valid_seq_lens_fr[start:end]\n",
    "        tgt_batch, tgt_seq_lens = valid_en[start:end], valid_seq_lens_en[start:end]\n",
    "        real_batch_size = len(src_batch)\n",
    "        (src_batch, src_seq_lens_batch,\n",
    "         tgt_x_batch, tgt_y_batch, tgt_seq_lens_batch) = pad_batch(src_batch, src_seq_lens,\n",
    "                                                                   tgt_batch, tgt_seq_lens,\n",
    "                                                                   pad_val=pad_token_id)\n",
    "        output = attention_model(src_batch, src_seq_lens_batch, tgt_x_batch, tgt_seq_lens_batch, training=False)\n",
    "        loss = seq2seq_loss(output, tgt_y_batch, tgt_seq_lens_batch)\n",
    "\n",
    "        if batch_idx % 1 == 0 or batch_idx == len(valid_en) - 1:\n",
    "            print_line(f'Epoch {epoch + 1} / {num_epoch} - Step {batch_idx + 1} / {n_valid_batch} - loss: {loss:.4f}')\n",
    "\n",
    "        valid_loss += loss * real_batch_size\n",
    "    train_epoch_loss = epoch_loss / n_training_samples\n",
    "    valid_epoch_loss = valid_loss / len(valid_en)\n",
    "    attention_train_losses.append(train_epoch_loss)\n",
    "    attention_valid_losses.append(valid_epoch_loss)\n",
    "    print(f'\\rEpoch {epoch + 1} / {num_epoch} - Step {len(attention_train_batch_sampler)} / {len(attention_train_batch_sampler)} - train loss: {train_epoch_loss:.4f} - valid loss: {valid_epoch_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you implement everything correctly, the valid loss will be around 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"seq2seq_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder_3 (Encoder)         multiple                  1576448   \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| embedding_6 (Embedding)    multiple                  1280000  |\n",
      "|                                                               |\n",
      "| gru_6 (GRU)                multiple                  296448   |\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder_3 (Encoder)         multiple                  1576448   \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| embedding_6 (Embedding)    multiple                  1280000  |\n",
      "|                                                               |\n",
      "| gru_6 (GRU)                multiple                  296448   |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      " decoder_1 (Decoder)         multiple                  4146448   \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| embedding_7 (Embedding)    multiple                  1280000  |\n",
      "|                                                               |\n",
      "| gru_7 (GRU)                multiple                  296448   |\n",
      "|                                                               |\n",
      "| dropout_3 (Dropout)        multiple                  0        |\n",
      "|                                                               |\n",
      "| dense_3 (Dense)            multiple                  2570000  |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      "=================================================================\n",
      "Total params: 5722896 (21.83 MB)\n",
      "Trainable params: 5722896 (21.83 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary(expand_nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "592475e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"seq2seq_attention_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder_4 (Encoder)         multiple                  1576448   \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| embedding_8 (Embedding)    multiple                  1280000  |\n",
      "|                                                               |\n",
      "| gru_8 (GRU)                multiple                  296448   |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder_4 (Encoder)         multiple                  1576448   \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| embedding_8 (Embedding)    multiple                  1280000  |\n",
      "|                                                               |\n",
      "| gru_8 (GRU)                multiple                  296448   |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      " attention_decoder_2 (Atten  multiple                  6706448   \n",
      " tionDecoder)                                                    \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| embedding_9 (Embedding)    multiple                  1280000  |\n",
      "|                                                               |\n",
      "| gru_9 (GRU)                multiple                  296448   |\n",
      "|                                                               |\n",
      "| attention_2 (Attention)    multiple                  0        |\n",
      "|                                                               |\n",
      "| dropout_4 (Dropout)        multiple                  0        |\n",
      "|                                                               |\n",
      "| dense_4 (Dense)            multiple                  5130000  |\n",
      "|                                                               |\n",
      "| concatenate_2 (Concatenat  multiple                  0        |\n",
      "| e)                                                            |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      "=================================================================\n",
      "Total params: 8282896 (31.60 MB)\n",
      "Trainable params: 8282896 (31.60 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "attention_model.summary(expand_nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "x = np.arange(1, len(train_losses) + 1)\n",
    "plt.plot(x, train_losses, label='Train loss')\n",
    "plt.plot(x, valid_losses, label='Valid loss')\n",
    "plt.legend()\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.xticks(x)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "005c66f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "x = np.arange(1, len(attention_train_losses) + 1)\n",
    "plt.plot(x, attention_train_losses, label='Attention Train loss')\n",
    "plt.plot(x, attention_valid_losses, label='Attention Valid loss')\n",
    "plt.legend()\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.xticks(x)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Translate French to English (15 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "sos_token_id = en_tokenizer.token_to_id('<s>')\n",
    "eos_token_id = en_tokenizer.token_to_id('</s>')\n",
    "max_pred_len = 200\n",
    "def translate(encoder: 'Encoder', decoder: 'Decoder', fr_sentences: List[List[int]], attention = False):\n",
    "    \"\"\" Translate the src (French) sentences to English sentences.\n",
    "        This is a recursive translation.\n",
    "        \n",
    "    Args:\n",
    "        encoder: The encoder part in seq2seq\n",
    "        decoder: The decoder part in seq2seq\n",
    "        fr_sentences: The src token ids of all sentences\n",
    "    Returns:\n",
    "        pred_sentences: The predicted string sentences\n",
    "    \"\"\"\n",
    "    n = len(fr_sentences)\n",
    "    pred_sentences = []\n",
    "    for i, src_ids in enumerate(fr_sentences):\n",
    "        print_line(f'{i + 1} / {n}')\n",
    "        # Shape of src_ids: (1 x seq_len)\n",
    "        src_ids = tf.expand_dims(tf.convert_to_tensor(src_ids, dtype=tf.int64), axis=0)\n",
    "        # pred is the prediction token ids. It starts with <s>\n",
    "        pred = [sos_token_id]\n",
    "        # Start your code here\n",
    "        # Step 1. Calculate the encoder outputs and hidden states (similar to seq2seq2 model)\n",
    "        # Step 2. Run a while loop when the last token in pred is not eos_token_id and the length of pred is less than max_pred_len\n",
    "        # Step 3.     In the while loop, build the input (cur_token) of decoder: the last token of pred. Shape (batch_size, ) -> (1, )\n",
    "        #             For example, if the current pred is [1, 50, 21, 8], the cur_token is [8]\n",
    "        # Step 4.     In the while loop, use decoder.predict to get the decoder output\n",
    "        # Step 5.     In the while loop, find the index with the maximum value. Then you can call tf.squeeze and numpy() to get the index\n",
    "        # Step 6.     In the while loop, append the predicted token to pred\n",
    "        # Step 7. Use en_tokenizer to decode the id to strings: pred_sentence\n",
    "        enc_outputs, state = encoder(src_ids, None)\n",
    "        while pred[-1] != eos_token_id and len(pred) <= max_pred_len:\n",
    "            cur_token = tf.ensure_shape(tf.convert_to_tensor([pred[-1]], dtype='int64'), (1,))\n",
    "            # Since the Decoder and AttentionDecoder layer require different inputs, \n",
    "            # need to check if we are using attention.\n",
    "            if attention:\n",
    "                dec_outputs, state = decoder.predict(cur_token, state, enc_outputs)\n",
    "            else:\n",
    "                dec_outputs, state = decoder.predict(cur_token, state)\n",
    "            index = tf.squeeze(tf.math.argmax(tf.squeeze(dec_outputs))).numpy()\n",
    "            pred.append(index)\n",
    "        # End\n",
    "        pred_sentence = en_tokenizer.decode(pred)\n",
    "        pred_sentences.append(pred_sentence)\n",
    "    print_line('\\n')\n",
    "    return pred_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a0bf2f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8597 / 8597\n"
     ]
    }
   ],
   "source": [
    "model.set_training(False)\n",
    "\n",
    "test_pred = translate(model.encoder, model.decoder, fr_sentences=test_fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "65a3bcbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8597 / 8597\n"
     ]
    }
   ],
   "source": [
    "attention_model.set_training(False)\n",
    "\n",
    "attention_test_pred = translate(attention_model.encoder, attention_model.decoder, fr_sentences=test_fr, attention = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Demonstrate 10 translation examples (5 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "French:  les bonnes équipes envoient ces informations de façon à ce que les joueurs puissent s'en servir.\n",
      "True English:  the good teams stream it in a way that the players can use.\n",
      "1 / 1\n",
      "Translated English (seq2seq model):  the guys on the screen have to be able to make these kinds of signals that are going to be able to do this.\n",
      "1 / 1\n",
      "Translated English (seq2seq + attention model):  the good teams send these information to what gamers can use.\n",
      "\n",
      "French:  merci.\n",
      "True English:  thank you.\n",
      "1 / 1\n",
      "Translated English (seq2seq model):  thank you.\n",
      "1 / 1\n",
      "Translated English (seq2seq + attention model):  thank you.\n",
      "\n",
      "French:  il y a eu plusieurs cas où c'était vraiment juste.\n",
      "True English:  there have been several close calls.\n",
      "1 / 1\n",
      "Translated English (seq2seq model):  there were many other cases, which was really right.\n",
      "1 / 1\n",
      "Translated English (seq2seq + attention model):  there were several cases where it was really just.\n",
      "\n",
      "French:  mes prières vous accompagnent dans votre combat.\n",
      "True English:  my prayers are with you for your fight.\n",
      "1 / 1\n",
      "Translated English (seq2seq model):  your prayers are in your throat.\n",
      "1 / 1\n",
      "Translated English (seq2seq + attention model):  my prayers will come up with your battles.\n",
      "\n",
      "French:  et la question était : comment la technologie pourrait, les nouvelles technologies, y être ajoutée ?\n",
      "True English:  and the question was: how could technology, new technology,  be added to that?\n",
      "1 / 1\n",
      "Translated English (seq2seq model):  and the question was, how technology could be, new technology, can be?\n",
      "1 / 1\n",
      "Translated English (seq2seq + attention model):  and the question was, how technology could, how technology could, are you addered?\n",
      "\n",
      "French:  combien d'entre vous ont vu l'ordinateur watson d'ibm gagner à jeopardy ?\n",
      "True English:  i mean, how many of you saw the winning of jeopardy  by ibm's watson?\n",
      "1 / 1\n",
      "Translated English (seq2seq model):  how many of you have seen a computer programmer?\n",
      "1 / 1\n",
      "Translated English (seq2seq + attention model):  how many of you have seen the computer, how many of you have seen the computer?\n",
      "\n",
      "French:  j'ai travaillé dans une mine de charbon -- dangereux.\n",
      "True English:  i worked in a coal mine --  dangerous.\n",
      "1 / 1\n",
      "Translated English (seq2seq model):  i worked in a factory that i grew up.\n",
      "1 / 1\n",
      "Translated English (seq2seq + attention model):  i worked in a coal mine -- dangerous.\n",
      "\n",
      "French:  n'importe qui d'autre l'aimerait aussi.\n",
      "True English:  somebody else would love about this woman.\n",
      "1 / 1\n",
      "Translated English (seq2seq model):  anyone else would love to be too.\n",
      "1 / 1\n",
      "Translated English (seq2seq + attention model):  any other would love to love it as well.\n",
      "\n",
      "French:  c'est tragique que les nord-coréens aient à cacher leurs identités et affronter tant de choses seulement pour survivre.\n",
      "True English:  it's tragic that north koreans have to hide their identities  and struggle so hard just to survive.\n",
      "1 / 1\n",
      "Translated English (seq2seq model):  it's been the only way to the north pole, and the only thing that they have been used to be very hard to have to be used to live.\n",
      "1 / 1\n",
      "Translated English (seq2seq + attention model):  it's tragic that the north koreans have to hide their identities and confront them so much for a living.\n",
      "\n",
      "French:  la glace que je photographie dans les icebergs est parfois très jeune -- deux milles ans.\n",
      "True English:  some of the ice in the icebergs that i photograph is very young --  a couple thousand years old.\n",
      "1 / 1\n",
      "Translated English (seq2seq model):  the ice of the glacier's very rare, i found five percent of the last few days.\n",
      "1 / 1\n",
      "Translated English (seq2seq + attention model):  ice i photographed in the ibot in the jiceibus, sometimes very young.\n",
      "\n",
      "French:  nous y avons exposé six différentes sortes de confitures, ou bien 24 sortes différentes, et nous avons observé deux choses : premièrement, dans quel cas les gens allaient-ils plus volontiers s'arrêter pour goûter la confiture ?\n",
      "True English:  we there put out six different flavors of jam  or 24 different flavors of jam,  and we looked at two things:  first, in which case  were people more likely to stop, sample some jam?\n",
      "1 / 1\n",
      "Translated English (seq2seq model):  we've been six different kinds of different kinds of things, and we were going to have a lot of other people, and then we have a lot of other people, and then we can't see the monkeys, and they have a lot of other people who are going to have a good-time, or three-dimensional, so you can't do it.\n",
      "1 / 1\n",
      "Translated English (seq2seq + attention model):  we have exposed six different kinds of speakers, or 24 different kinds, and we looked at two things, first, in which people were going to stop for a confession?\n",
      "\n",
      "French:  cependant, on envoie chacun d'entre eux, y compris moi-même, dans le monde, avec l’avertissement : « sois parfait.\n",
      "True English:  what we do though is we send each one of them, including myself,  out into the world  with the admonition, be perfect.\n",
      "1 / 1\n",
      "Translated English (seq2seq model):  but then we put them in every morning, and we're all in the first, with the god, in the case of the first.\n",
      "1 / 1\n",
      "Translated English (seq2seq + attention model):  however, we send each of them, including me, in the world, with a warning, and the warning, \"be perfect.\n",
      "\n",
      "French:  rendez-vous compte, ces gens n'avaient rien, et ils avaient tellement peur, ils voulaient abandonner mais la femme au centre les a rassemblés pour qu'ils persévèrent, et les abolitionnistes sur le terrain les ont aidés à obtenir leur propre bail pour une carrière, afin qu'ils fassent, à présent, le même travail éreintant, mais c'est pour eux qu'ils le font et ils sont payés pour ça, et ils le font en toute liberté.\n",
      "True English:  i mean, these people had nothing,  and they were so petrified, they wanted to give up,  but the woman in the center rallied for them to persevere,  and abolitionists on the ground  helped them get a quarry lease of their own,  so that now they do the same back-breaking work,  but they do it for themselves, and they get paid for it,  and they do it in freedom.\n",
      "1 / 1\n",
      "Translated English (seq2seq model):  find out that they were all these women, they were all of their jobs, and they were not allowed to be a lawyer, and they were to be a lawyer, and they were to ask, and they were to ask, and they were to ask, and they were to be a lawyer, and they were to ask, and they were to be the same thing, and they were to ask for what they wanted to do, and they were to ask for the women, and they were to be the same.\n",
      "1 / 1\n",
      "Translated English (seq2seq + attention model):  you know, these people have nothing, and they had so scared, and they would have to give up, but the woman to the center and the center of the center and the abolitioners on the ground, that they helped me with their own brad for a career, so that they do now, the same thing that was, and they're paid to be paid for that, and they're paid for that, and they're paid for that, and they're paid for that, and they're paid for that, and they're paid for that, and they're paid for that, and they're paid for that, and they're paid for that, and they're paid for that, and they're paid for that, and they're paid for that, and they're paid for that, and they're paid for that, and they're paid for that, and they're paid for that, and they're paid for that, and they're paid for that, and they\n",
      "\n",
      "French:  vous vous souvenez du feu ?\n",
      "True English:  remember fire?\n",
      "1 / 1\n",
      "Translated English (seq2seq model):  do you remember the fire?\n",
      "1 / 1\n",
      "Translated English (seq2seq + attention model):  remember the gun?\n",
      "\n",
      "French:  c'est un de mes plans d'action. c'est ce que je veux faire.\n",
      "True English:  now this is one of my plans. this is what i want to do.\n",
      "1 / 1\n",
      "Translated English (seq2seq model):  this is a kind of my lab. i want to do that.\n",
      "1 / 1\n",
      "Translated English (seq2seq + attention model):  that's one of my plans. it's what i want to do.\n",
      "\n",
      "French:  nous pouvons peut-être la voir comme du changement.\n",
      "True English:  maybe we can see it as change.\n",
      "1 / 1\n",
      "Translated English (seq2seq model):  we can see that the more changes can change.\n",
      "1 / 1\n",
      "Translated English (seq2seq + attention model):  we can maybe see it as change.\n",
      "\n",
      "French:  on ne peut pas espérer le résoudre du jour au lendemain.\n",
      "True English:  we can't expect to solve it overnight.\n",
      "1 / 1\n",
      "Translated English (seq2seq model):  we can't wait better day to go back.\n",
      "1 / 1\n",
      "Translated English (seq2seq + attention model):  you can't hope to solve the day after the next day.\n",
      "\n",
      "French:  ms: et c'est une société de plusieurs millions de dollars.\n",
      "True English:  ms: and that's a multi-million dollar corporation.\n",
      "1 / 1\n",
      "Translated English (seq2seq model):  ms: and it's a million dollars for a million dollars.\n",
      "1 / 1\n",
      "Translated English (seq2seq + attention model):  ms: and it's a multi-boned society.\n",
      "\n",
      "French:  on prend des armoires chippendale qu'on transforme en gratte-ciel, et les gratte-ciel peuvent être des châteaux médiévaux en verre.\n",
      "True English:  we take chippendale armoires  and we turned those into skyscrapers,  and skyscrapers can be medieval castles made out of glass.\n",
      "1 / 1\n",
      "Translated English (seq2seq model):  we take a metal-speaking toy, and we can put it in the garage, and we can use it to be a little bit like a bass in the wall.\n",
      "1 / 1\n",
      "Translated English (seq2seq + attention model):  we take low-power pressure of that, you turn free to free, and scratch free, can't medititories.\n",
      "\n",
      "French:  et vous aimez ça.\n",
      "True English:  and you love it.\n",
      "1 / 1\n",
      "Translated English (seq2seq model):  and you love that.\n",
      "1 / 1\n",
      "Translated English (seq2seq + attention model):  and you like that.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.set_training(False)\n",
    "np.random.seed(6666)\n",
    "sample_num = 20 # Originally 10 but instructions specify to test 20 sentences\n",
    "# Start your code here\n",
    "# Use np.random.choice to sample 10 sentence indices. Remember to set correct replace\n",
    "# Print format:\n",
    "# 1.\n",
    "# French: ...\n",
    "# True English: ...\n",
    "# Translated English: ...\n",
    "# ------------------\n",
    "selection = np.random.choice(len(test_fr), size = sample_num, replace = False)\n",
    "for index in selection:\n",
    "    # Decode the sentences to print them to the screen.\n",
    "    fr_sent = fr_tokenizer.decode(test_fr[index])\n",
    "    en_sent = en_tokenizer.decode(test_en[index])\n",
    "    print(f\"French: {fr_sent}\")\n",
    "    print(f\"True English: {en_sent}\")\n",
    "    print(f\"Translated English (seq2seq model): {translate(model.encoder, model.decoder, [test_fr[index]])[0]}\")\n",
    "    print(f\"Translated English (seq2seq + attention model): {translate(attention_model.encoder, attention_model.decoder, [test_fr[index]], attention = True)[0]}\\n\")\n",
    "\n",
    "# End"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Compute the bleu score (5 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq2Seq BLEU: 6.56\n",
      "Seq2Seq + attention BLEU: 25.95\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "\n",
    "sacrebleu = evaluate.load('sacrebleu', cache_dir=dataset_path)\n",
    "# Start your code here\n",
    "# see https://huggingface.co/spaces/evaluate-metric/sacrebleu\n",
    "# Note: please understand the format and meaning of references.\n",
    "references = []\n",
    "for tokens in test_en:\n",
    "    # References are the ground truths. We only have one ground truth translation\n",
    "    # for each french sentence here, so create a reference array containing only\n",
    "    # the decoded ground truth english sentence and append it to references.\n",
    "    references.append([en_tokenizer.decode(tokens)])\n",
    "results = sacrebleu.compute(predictions = test_pred, references = references)\n",
    "attention_results = sacrebleu.compute(predictions = attention_test_pred, references = references)\n",
    "# End\n",
    "score = results['score']\n",
    "attention_score = attention_results['score']\n",
    "print(f\"Seq2Seq BLEU: {round(score, 2)}\")\n",
    "print(f\"Seq2Seq + attention BLEU: {round(attention_score, 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you implement everything correctly, the BLEU score will be around 7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion (5 Points)\n",
    "\n",
    "Including but not limited to: translation example analysis (case study), bleu score analysis, model structure / parameter analysis, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "Example Analysis:\n",
    "\n",
    "In the translation examples I printed, it's obvious that more context from throughout the sentence is taken into account - in general, the translated sentences from the attention-augments Seq2seq model had word choices aligning with the true translation, though there are still a few mistakes. For example, consider the following translation:\n",
    "\n",
    "\n",
    "French:  ms: et c'est une société de plusieurs millions de dollars.\n",
    "True English:  ms: and that's a multi-million dollar corporation.\n",
    "1 / 1\n",
    "Translated English (seq2seq model):  ms: and it's a million dollars for a million dollars.\n",
    "1 / 1\n",
    "Translated English (seq2seq + attention model):  ms: and it's a multi-boned society.\n",
    "\n",
    "\n",
    "Obviously, the attention model misses the mark here, but such awkward and incorrect choices are more abundant in the non-attention model.\n",
    "\n",
    "BLEU Scores:\n",
    "\n",
    "This is corroborated by the models' respective BLEU scores. The BLEU score of the attention model is about 4 times greater than the basic Seq2Seq model, indicating more accurate translations over the whole test corpus. \n",
    "\n",
    "Parameters and Structure:\n",
    "\n",
    "The attention model has about 1.5x more training parameters than the basic model, because the dense classification layer has more inputs as a result of the concatenation of the GRU layer output and the attention layer output. This difference also means that the decoder layer of the attention model requires both the output of the encoder layer AND the final state of its GRU component, instead of just the final state. \n",
    "\n",
    "However, these differences only resulted in an increase of required training time for equal training sets and number of epochs of about 9-10% (55 mins to 60 mins). For the experienced improvement in model performance, I'd say that is worth it.\n",
    "\n",
    "Training Performance:\n",
    "\n",
    "The non-attention model finished with a training error of about 2.5 and a validation loss of about 4. The attention model finished with a training loss of about 1.5 and a validation loss of about 3.1. \n",
    "\n",
    "In both cases, the training loss had not plateaued and would have continued to improve over more epochs. However, that would have likely led to overfitting.\n",
    "\n",
    "In both cases, the validation loss had plateaued by the end of training. The attention model bottomed out much earlier than the non-attention model (non-attention plateaued around epoch 12 while the attention did so around epoch 6). Indeed, the attention model showed signs of approaching overfitting conditions, as the validation loss actually increased for epoch 15. \n",
    "\n",
    "This indicates far more the improvement to model learning efficiency than the training times, since it took far less time for the attention model to reach its best validation loss as compared to the the non-attention model, and it had a better loss even then.\n",
    "\n",
    "Overall Conclusion:\n",
    "\n",
    "The addition of JUST target attending to source improved both Seq2Seq's learning efficiency and its final performance by very significant amounts. It is obvious that attention is a very useful tool for such tasks. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
